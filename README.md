# Error-Aware Ensemble QA: Exploiting Model Diversity for Robust Question Answering

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

A hierarchical ensemble architecture that exploits complementary failure modes across diverse language models for robust hybrid question answering. This system combines neuro-symbolic reasoning with error-aware fusion to achieve improved accuracy on structured information extraction tasks.

## ğŸ¯ Key Features

- **Error-Aware Ensemble Fusion**: Three-stage cascade (unanimous â†’ majority â†’ feature-based routing) that outperforms naive voting
- **Model Diversity Exploitation**: Each model contributes unique successes; ensemble achieves 48% EM vs 42% best single model (+6pp)
- **Hybrid Neuro-Symbolic Architecture**: Adaptive routing between symbolic pattern matching and neural generation
- **Dynamic Rule Extraction**: Automatic mining of symbolic reasoning patterns from training data
- **Multi-Model Support**: Llama-3.2-3B, Mistral-7B-Instruct-v0.3, Gemma-1.1-7B-it with 8-bit quantization

## ğŸ“Š Performance Highlights

On the challenging DROP dataset (50-query validation):

| Configuration | EM (%) | Unique Contributions |
|---------------|--------|---------------------|
| Llama-3.2-3B | 36.0 | 5 queries |
| Mistral-7B | 40.0 | 7 queries |
| Gemma-1.1-7B | 42.0 | 10 queries |
| **Error-Aware Ensemble** | **48.0** | **+6pp improvement** |
| Theoretical Maximum | 76.0 | 38/50 recoverable |

**Fusion Strategy Distribution:**
- 26% queries: Unanimous agreement (all models align)
- 36% queries: Majority voting (2/3 models agree)
- 38% queries: Error-aware routing (feature-based model selection)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Ensemble Orchestration                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Llama-3B   â”‚  â”‚ Mistral-7B  â”‚  â”‚  Gemma-7B   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                 â”‚                 â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                         â†“                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚  Error-Aware Fusion â”‚                    â”‚
â”‚              â”‚  â€¢ Unanimous (26%)  â”‚                    â”‚
â”‚              â”‚  â€¢ Majority (36%)   â”‚                    â”‚
â”‚              â”‚  â€¢ Routing (38%)    â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Adaptive Control Module     â”‚
         â”‚   â€¢ Query complexity analysis â”‚
         â”‚   â€¢ Resource monitoring       â”‚
         â”‚   â€¢ Pathway routing           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â†“                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Symbolic   â”‚              â”‚   Neural    â”‚
â”‚  Reasoning  â”‚ â†â”€â”€Hybridâ”€â”€â†’ â”‚  Retriever  â”‚
â”‚  â€¢ Rules    â”‚              â”‚  â€¢ LLM      â”‚
â”‚  â€¢ Graphs   â”‚              â”‚  â€¢ Few-shot â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- CUDA-capable GPU (16GB+ VRAM recommended)
- 32GB system RAM

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/error-aware-ensemble-qa.git
cd error-aware-ensemble-qa

# Create virtual environment
conda create -n ensemble_qa python=3.9
conda activate ensemble_qa

# Install dependencies
pip install -r requirements.txt

# Download SpaCy models
python -m spacy download en_core_web_sm
python -m spacy download en_core_web_md
```

### Download Datasets

Due to size constraints, datasets are not included in the repository. Download them separately:

```bash
# Create data directory
mkdir -p data

# Download DROP dataset
wget https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset_dev.json -O data/drop_dataset_dev.json

# Download HotpotQA dataset
wget http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_dev_distractor_v1.json -O data/hotpot_dev_distractor_v1.json
```

Small reference files (few-shot examples, rules) are included in `data/`.

### Basic Usage

**Single-Model Mode:**
```bash
python main.py --dataset drop --samples 50
```

**Ensemble Mode:**
```bash
# Modify src/config/config.yaml:
# ensemble.enabled: true

python main.py --dataset drop --samples 50 --show-progress
```

**Run Ablation Studies:**
```bash
python main.py --dataset drop --samples 50 --run-ablation
```

## ğŸ“ Project Structure

```
error-aware-ensemble-qa/
â”œâ”€â”€ main.py                      # Entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ LICENSE                      # MIT License
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.yaml          # Main configuration
â”‚   â”‚   â”œâ”€â”€ ablation_config.yaml # Ablation study configs
â”‚   â”‚   â””â”€â”€ resource_config.yaml # Resource thresholds
â”‚   â”‚
â”‚   â”œâ”€â”€ system/
â”‚   â”‚   â”œâ”€â”€ ensemble_manager.py       # Multi-model orchestration
â”‚   â”‚   â”œâ”€â”€ system_control_manager.py # Adaptive routing
â”‚   â”‚   â””â”€â”€ response_aggregator.py    # Response formatting
â”‚   â”‚
â”‚   â”œâ”€â”€ reasoners/
â”‚   â”‚   â”œâ”€â”€ neural_retriever.py                # LLM inference
â”‚   â”‚   â”œâ”€â”€ networkx_symbolic_reasoner_base.py # Base symbolic engine
â”‚   â”‚   â””â”€â”€ networkx_symbolic_reasoner_drop.py # DROP-specific logic
â”‚   â”‚
â”‚   â”œâ”€â”€ integrators/
â”‚   â”‚   â””â”€â”€ hybrid_integrator.py      # Symbolic-neural fusion
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ ensemble_helpers.py       # Error-aware fusion logic
â”‚   â”‚   â”œâ”€â”€ rule_extractor.py         # Dynamic rule mining
â”‚   â”‚   â”œâ”€â”€ evaluation.py             # Metrics computation
â”‚   â”‚   â”œâ”€â”€ metrics_collector.py      # Performance tracking
â”‚   â”‚   â”œâ”€â”€ device_manager.py         # GPU/CPU management
â”‚   â”‚   â””â”€â”€ dimension_manager.py      # Embedding alignment
â”‚   â”‚
â”‚   â””â”€â”€ queries/
â”‚       â”œâ”€â”€ query_expander.py         # Query complexity analysis
â”‚       â””â”€â”€ query_logger.py           # Query logging
â”‚
â”œâ”€â”€ data/                        # Small reference files only
â”‚   â”œâ”€â”€ drop_few_shot_examples.json
â”‚   â”œâ”€â”€ rules_drop.json
â”‚   â”œâ”€â”€ rules_hotpotqa.json
â”‚   â””â”€â”€ empty_rules.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ analyze_model_diversity.py   # Validation analysis tools
â”‚
â””â”€â”€ Manuscript/                  # Research paper (LaTeX)
    â””â”€â”€ main.tex
```

## ğŸ”§ Configuration

Key configuration options in `src/config/config.yaml`:

```yaml
# Ensemble mode
ensemble:
  enabled: true              # Set to false for single-model
  batched: true              # Process all queries per model
  models:
    - "llama-3.2-3b"
    - "mistral-7b"
    - "gemma-1.1-7b"
  fusion_strategy: "error_aware"  # Options: error_aware, confidence, majority_vote

# Model-specific settings
model_configs:
  "llama-3.2-3b":
    model_name: "meta-llama/Llama-3.2-3B"
    few_shot_examples_path: "data/drop_few_shot_examples.json"

# Feature flags
use_drop_few_shots: 1        # Enable few-shot learning for DROP
```

## ğŸ“ˆ Validation Results

Comprehensive validation on 50 DROP queries demonstrates:

**Model Diversity:**
- 38/50 queries solvable by at least one model (76% theoretical maximum)
- Each model contributes 5-10 unique correct answers
- Low error correlation validates complementary strengths

**Ensemble Efficiency:**
- Achieves 24/50 correct (48% EM) vs 21/50 best single (42%)
- 63.2% efficiency in recovering model diversity (24/38)
- 2 ensemble-only successes (all singles failed)
- 16 missed opportunities (room for improvement)

**Fusion Cascade Contribution:**
- Unanimous: 13/50 (26%) - All models agree
- Majority: 18/50 (36%) - 2/3 models agree
- Error-aware: 19/50 (38%) - Feature-based routing required

## ğŸ§ª Running Experiments

**Reproduce Validation Results:**
```bash
# Step 1: Run each model individually
python main.py --dataset drop --samples 50 > logs/llama_validation.txt
# (Edit config.yaml to switch models)

# Step 2: Run ensemble
python main.py --dataset drop --samples 50 > logs/ensemble_validation.txt

# Step 3: Analyze diversity
python scripts/analyze_model_diversity.py
```

**Ablation Studies:**
```bash
# Compare fusion strategies
python main.py --dataset drop --samples 50 --run-ablation

# Test without few-shot learning
# (Set use_drop_few_shots: 0 in config.yaml)
python main.py --dataset drop --samples 50
```

## ğŸ“Š Evaluation Metrics

- **Exact Match (EM)**: Percentage of predictions matching ground truth exactly
- **F1 Score**: Token-level overlap between prediction and ground truth
- **Fusion Efficiency**: (Ensemble correct) / (Theoretical maximum)
- **Recovery Rate**: Queries where ensemble succeeds but at least one single model fails

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

1. **Confidence Calibration**: Improve model probability alignment
2. **Feature Engineering**: Add entity density, question complexity signals
3. **Memory Optimization**: Enable efficient deployment of multiple 7B models
4. **Meta-Learning**: Learn fusion weights from validation performance

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@article{hakim2025error,
  title={Exploiting Model Diversity Through Error-Aware Ensemble Fusion: A Hierarchical Architecture for Robust Hybrid Question Answering},
  author={Hakim, Safayat Bin and Song, Houbing Herbert},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2025}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- DROP dataset: Dua et al., "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs"
- HotpotQA dataset: Yang et al., "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"
- Model providers: Meta (Llama), Mistral AI (Mistral), Google (Gemma)

## ğŸ“ Contact

For questions or collaborations:
ğŸ“§ safayat [dot] b [dot] hakim [at] gmail [dot] com

---

**Status**: Research code - Validated on DROP dataset with 50-query validation set. Ensemble achieves +6pp improvement over best single model.
